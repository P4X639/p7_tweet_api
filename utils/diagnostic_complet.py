# Script de diagnostic exhaustif pour analyser le probl√®me de performance
import os
import requests
import json
import mlflow
from mlflow.tracking import MlflowClient

# Configuration
API_BASE_URL = "http://localhost:8000"
DAGSHUB_USERNAME = "ncolin.online"
DAGSHUB_REPO = "P7_tweet"
MODEL_RUN_ID = "0b567034e22342308bd7e3835378035a"

def setup_mlflow():
    """Configuration MLflow"""
    mlflow_uri = f"https://dagshub.com/{DAGSHUB_USERNAME}/{DAGSHUB_REPO}.mlflow"
    mlflow.set_tracking_uri(mlflow_uri)
    
    # Configuration auth
    os.environ["MLFLOW_TRACKING_USERNAME"] = DAGSHUB_USERNAME
    os.environ["MLFLOW_TRACKING_PASSWORD"] = os.getenv("DAGSHUB_TOKEN", "")
    
    return MlflowClient()

def analyze_artifacts():
    """Analyser tous les artifacts disponibles"""
    print("=" * 60)
    print("üîç ANALYSE DES ARTIFACTS")
    print("=" * 60)
    
    try:
        client = setup_mlflow()
        
        # Lister tous les artifacts
        artifacts = client.list_artifacts(MODEL_RUN_ID)
        print(f"Artifacts disponibles pour le run {MODEL_RUN_ID}:")
        
        for artifact in artifacts:
            print(f"üìÅ {artifact.path}")
            if artifact.is_dir:
                # Lister le contenu des dossiers
                sub_artifacts = client.list_artifacts(MODEL_RUN_ID, artifact.path)
                for sub_artifact in sub_artifacts:
                    print(f"   üìÑ {sub_artifact.path} (taille: {sub_artifact.file_size} bytes)")
            else:
                print(f"   üìÑ Fichier direct (taille: {artifact.file_size} bytes)")
        
        return artifacts
        
    except Exception as e:
        print(f"‚ùå Erreur analyse artifacts: {e}")
        return []

def analyze_run_metadata():
    """Analyser les m√©tadonn√©es du run d'entra√Ænement"""
    print("\n" + "=" * 60)
    print("üìä M√âTADONN√âES DU RUN D'ENTRA√éNEMENT")
    print("=" * 60)
    
    try:
        client = setup_mlflow()
        run = client.get_run(MODEL_RUN_ID)
        
        print("üìã Informations g√©n√©rales:")
        print(f"   Status: {run.info.status}")
        print(f"   Start time: {run.info.start_time}")
        print(f"   End time: {run.info.end_time}")
        
        print("\nüîß Param√®tres d'entra√Ænement:")
        for key, value in run.data.params.items():
            print(f"   {key}: {value}")
        
        print("\nüìà M√©triques d'entra√Ænement:")
        for key, value in run.data.metrics.items():
            print(f"   {key}: {value}")
        
        print("\nüè∑Ô∏è  Tags:")
        for key, value in run.data.tags.items():
            print(f"   {key}: {value}")
            
        return run.data
        
    except Exception as e:
        print(f"‚ùå Erreur analyse m√©tadonn√©es: {e}")
        return None

def analyze_api_model():
    """Analyser le mod√®le charg√© dans l'API"""
    print("\n" + "=" * 60)
    print("ü§ñ ANALYSE DU MOD√àLE DANS L'API")
    print("=" * 60)
    
    try:
        # Info mod√®le via API
        response = requests.get(f"{API_BASE_URL}/model/info", timeout=10)
        if response.status_code == 200:
            model_info = response.json()
            print("üìã Informations du mod√®le:")
            print(json.dumps(model_info, indent=2))
            
        # Health check
        response = requests.get(f"{API_BASE_URL}/health", timeout=10)
        if response.status_code == 200:
            health = response.json()
            print(f"\nüè• Sant√© de l'API:")
            print(f"   Status: {health['status']}")
            print(f"   Model loaded: {health['model_loaded']}")
            
    except Exception as e:
        print(f"‚ùå Erreur analyse API: {e}")

def test_prediction_consistency():
    """Tester la consistance des pr√©dictions"""
    print("\n" + "=" * 60)
    print("üéØ TEST DE CONSISTANCE DES PR√âDICTIONS")
    print("=" * 60)
    
    test_cases = [
        "le vol √©tait en retard, mais j'ai fais de belles rencontres",
        "Service excellent d'Air Paradis!",
        "Vol retard√© encore une fois!",
        "Vol parfait, √©quipage professionnel"
    ]
    
    for text in test_cases:
        print(f"\nüìù Test: '{text}'")
        
        results = []
        for i in range(3):
            try:
                response = requests.post(
                    f"{API_BASE_URL}/predict",
                    json={"text": text, "user_id": f"test_{i}"},
                    timeout=10
                )
                
                if response.status_code == 200:
                    result = response.json()
                    results.append(result)
                    print(f"   Essai {i+1}: {result['sentiment']} ({result['confidence']:.4f})")
                else:
                    print(f"   Essai {i+1}: Erreur {response.status_code}")
                    
            except Exception as e:
                print(f"   Essai {i+1}: Exception {e}")
        
        # Analyser la consistance
        if results:
            sentiments = [r['sentiment'] for r in results]
            confidences = [r['confidence'] for r in results]
            
            consistent_sentiment = len(set(sentiments)) == 1
            consistent_confidence = len(set(round(c, 4) for c in confidences)) == 1
            
            if consistent_sentiment and consistent_confidence:
                print("   ‚úÖ Pr√©dictions consistantes")
            else:
                print("   ‚ùå Pr√©dictions INCONSISTANTES")
                print(f"      Sentiments: {sentiments}")
                print(f"      Confidences: {[round(c, 4) for c in confidences]}")

def analyze_model_architecture():
    """Analyser l'architecture du mod√®le (n√©cessite d'acc√©der au container)"""
    print("\n" + "=" * 60)
    print("üèóÔ∏è  ANALYSE DE L'ARCHITECTURE DU MOD√àLE")
    print("=" * 60)
    
    print("‚ÑπÔ∏è  Pour analyser l'architecture, ex√©cutez dans le container:")
    print("   docker-compose exec api python -c \"")
    print("   from services.dagshub_service import DagsHubService")
    print("   service = DagsHubService()")
    print("   service.test_connection()")
    print("   if service.model:")
    print("       print('Input shape:', service.model.input_shape)")
    print("       service.model.summary()")
    print("   \"")

def recommendations():
    """Recommandations bas√©es sur l'analyse"""
    print("\n" + "=" * 60)
    print("üí° RECOMMANDATIONS")
    print("=" * 60)
    
    print("1. üîß PROBL√àME PRINCIPAL IDENTIFI√â:")
    print("   Le tokenizer/vectorizer d'entra√Ænement N'EST PAS utilis√© en production")
    print("   Fichier: 'nn_model_tokenizer_none_lstm.pkl' disponible mais non charg√©")
    
    print("\n2. üö® ACTIONS PRIORITAIRES:")
    print("   a) Modifier services/dagshub_service.py pour charger le tokenizer")
    print("   b) Remplacer la vectorisation actuelle par le vrai tokenizer")
    print("   c) V√©rifier l'input_shape du mod√®le")
    
    print("\n3. üìã CODE √Ä AJOUTER:")
    print("   ```python")
    print("   # Dans load_model_from_artifacts()")
    print("   tokenizer_path = client.download_artifacts(")
    print("       self.model_run_id, 'nn_model_tokenizer_none_lstm.pkl', temp_dir)")
    print("   import pickle")
    print("   with open(tokenizer_path, 'rb') as f:")
    print("       self.tokenizer = pickle.load(f)")
    print("   ```")
    
    print("\n4. üéØ R√âSULTAT ATTENDU:")
    print("   Avec le bon tokenizer, vous devriez retrouver ~82% d'accuracy")

def main():
    """Diagnostic complet"""
    print("üöÄ DIAGNOSTIC EXHAUSTIF DU SYST√àME D'ANALYSE DE SENTIMENT")
    print("=" * 80)
    
    # 1. Analyser les artifacts
    artifacts = analyze_artifacts()
    
    # 2. Analyser les m√©tadonn√©es du run
    run_data = analyze_run_metadata()
    
    # 3. Analyser le mod√®le dans l'API
    analyze_api_model()
    
    # 4. Tester la consistance
    test_prediction_consistency()
    
    # 5. Analyser l'architecture (instructions)
    analyze_model_architecture()
    
    # 6. Recommandations
    recommendations()
    
    print("\n" + "=" * 80)
    print("üéØ DIAGNOSTIC TERMIN√â")
    print("Le probl√®me principal est l'absence du tokenizer d'entra√Ænement")
    print("Solution: Charger et utiliser 'nn_model_tokenizer_none_lstm.pkl'")
    print("=" * 80)

if __name__ == "__main__":
    main()